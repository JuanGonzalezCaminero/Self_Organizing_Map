{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_vector(vector):\n",
    "    '''\n",
    "    Returns the normalized vector of the provided one, a length 1\n",
    "    vector with the same direction as the original.\n",
    "    '''\n",
    "    vector = np.array(vector)\n",
    "    return (vector/math.sqrt(np.sum(pow(vector, 2)))).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extended_normalization(vector):\n",
    "    '''\n",
    "    When two vectors of different lengths but in the same direction are normalized, \n",
    "    the result will be the same for both of them.\n",
    "    \n",
    "    In order to avoid collisions of normalized vectors, an extended normalization can\n",
    "    be applied, where an extra dimension is added to the vector to be normalized. By\n",
    "    adding a component of length 1 in the new dimension and normalizing the result,\n",
    "    it is ensured that no two vectors which were originally in the same dimensions\n",
    "    will produce the same output.\n",
    "    '''\n",
    "    vector = np.append(vector, 1)\n",
    "    return (vector/math.sqrt(np.sum(pow(vector, 2)))).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_unit_vector(components):\n",
    "    '''\n",
    "    Returns a random vector of length 1 with the required number of components\n",
    "    '''\n",
    "    return normalize_vector([random.random() for i in range(components)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SOM:\n",
    "    def __init__ (self, dimensions, topology='rectangular', max_iter=100):\n",
    "        '''\n",
    "        dimensions - Array-like, containing the size of the output\n",
    "        layer in each dimension.\n",
    "        \n",
    "        topology - The neighborhood relation between output-layer neurons.\n",
    "        The default topology is rectangular. A future improvement would be\n",
    "        to implement a hexagonal topology option.\n",
    "        \n",
    "        max_iter - The maximum number of epochs before the algorithm stops\n",
    "        '''\n",
    "        self.dimensions = dimensions\n",
    "        self.output_layer = None\n",
    "        self.max_iter = max_iter\n",
    "        self.topology = topology\n",
    "        #Output layer indexes is the cartesian product of the lists containing\n",
    "        #the possible indexes to each dimension of the output layer matrix. That\n",
    "        #is, it is a list containing the indexes to all the positions of the \n",
    "        #output layer. It is used to iterate over the output layer, since the \n",
    "        #number of dimensions it will have is unknown before the execution\n",
    "        indexes_list = [list(range(i)) for i in self.dimensions]\n",
    "        self.output_layer_indexes = itertools.product(*indexes_list)\n",
    "        return\n",
    "    def __weight_initialization(self, num_attr):\n",
    "        '''\n",
    "        Initializes the output layer to a matrix with the dimensions specified\n",
    "        for this map, filled with random unit vectors of dimension num_attr\n",
    "        \n",
    "        num_attr - The number of attributes of the instances this network will\n",
    "        be trained with\n",
    "        '''\n",
    "        self.output_layer = np.zeros(self.dimensions, dtype=object)\n",
    "        for i in self.output_layer_indexes:\n",
    "            self.output_layer[i] = get_random_unit_vector(num_attr)\n",
    "        #Maybe cast the output layer to a regular list here?\n",
    "        return\n",
    "    def __get_output(self, instance):\n",
    "        '''\n",
    "        Calculates the output of each neuron for the provided instance.\n",
    "        Returns a matrix with the same dimensions as the output layer\n",
    "        containing the outputs\n",
    "        '''\n",
    "        output_matrix = np.zeros(self.dimensions)\n",
    "        for i in self.output_layer_indexes:\n",
    "            output_matrix[i] = distance.euclidean(instance, self.output_layer[i])\n",
    "        return output_matrix\n",
    "    def __get_neighbors(self, index, radius):\n",
    "        '''\n",
    "        Returns a matrix containing the indexes of the neurons in distance radius\n",
    "        to the one specified by index.\n",
    "        In order to implement different possible topologies, this should have a different\n",
    "        way of computing the indexes depending on that\n",
    "        '''\n",
    "        return\n",
    "    def fit(self, X):\n",
    "        '''\n",
    "        Initializes the output layer neurons to random unit vectors, normalizes\n",
    "        the input vectors, and applies the learning algorithm to the input data, X\n",
    "        \n",
    "        X - The data to train the algorithm on\n",
    "        '''\n",
    "        #Since extended normalization will be used, the inputs will have an extra \n",
    "        #dimension, which is why I add 1 here so the output layer vectors will have\n",
    "        #the number of attributes of an instance plus 1 components\n",
    "        #Weight initialization\n",
    "        self.__weight_initialization(len(X[0]) + 1)\n",
    "        #Input data normalization\n",
    "        X = [extended_normalization(v) for v in X]\n",
    "        #Training\n",
    "        for epoch in range(self.max_iter):\n",
    "            #Chose a vector at random from the training data\n",
    "            input_vector = random.choice(X)\n",
    "            #Get the output for each neuron in the output layer\n",
    "            output_matrix = self.__get_output(input_vector)\n",
    "            #Get the index of the neuron that provides the smallest output\n",
    "            #Np unravel index gives us the multi-dimensional index to a matrix\n",
    "            #of the specified shape given the index into the flattened version of\n",
    "            #the matrix, which np.argmin returns\n",
    "            best_matching_unit = np.unravel_index(np.argmin(output_matrix, axis=None), \n",
    "                                                  output_matrix.shape)\n",
    "            #This would be another way to do it, testing should be done in order \n",
    "            #to determine which of the two is the most efficient. I would think this \n",
    "            #secong one is probably better as the matrix indexes are already computed\n",
    "            #best_matching_unit = self.output_layer_indexes[np.argmin(output_matrix)]\n",
    "            \n",
    "            \n",
    "        return\n",
    "    def predict(self, x):\n",
    "        '''\n",
    "        Determines the Best Matching Unit for the instance x, and returns the predicted\n",
    "        class for it based on the class associated to the neuron\n",
    "        '''\n",
    "        return\n",
    "    def print_map():\n",
    "        '''\n",
    "        Shows a graphical representation of the output layer\n",
    "        '''\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "som = SOM([10, 10])\n",
    "som.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1,2,3],\n",
    "        [1,1,1],\n",
    "        [2,3,4],\n",
    "        [4,2,4],\n",
    "        [2,2,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 2, 4]"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[[3],[1]],\n",
    "     [[0],[2]],\n",
    "     [[3],[3]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin([np.array(a)[i] for i in [(0,0),(0,1),(1,0),(1,1),(2,0),(2,1)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0, 0)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unravel_index(np.argmin(a, axis=None), a.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
