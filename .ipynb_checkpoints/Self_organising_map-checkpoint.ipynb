{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_vector(vector):\n",
    "    '''\n",
    "    Returns the normalized vector of the provided one, a length 1\n",
    "    vector with the same direction as the original.\n",
    "    '''\n",
    "    vector = np.array(vector)\n",
    "    return (vector/math.sqrt(np.sum(pow(vector, 2)))).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extended_normalization(vector):\n",
    "    '''\n",
    "    When two vectors of different lengths but in the same direction are normalized, \n",
    "    the result will be the same for both of them.\n",
    "    \n",
    "    In order to avoid collisions of normalized vectors, an extended normalization can\n",
    "    be applied, where an extra dimension is added to the vector to be normalized. By\n",
    "    adding a component of length 1 in the new dimension and normalizing the result,\n",
    "    it is ensured that no two vectors which were originally in the same dimensions\n",
    "    will produce the same output.\n",
    "    '''\n",
    "    vector = np.append(vector, 1)\n",
    "    return (vector/math.sqrt(np.sum(pow(vector, 2)))).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_unit_vector(components):\n",
    "    '''\n",
    "    Returns a random vector of length 1 with the required number of components\n",
    "    '''\n",
    "    return normalize_vector([random.random() for i in range(components)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SOM:\n",
    "    def __init__ (self, dimensions, topology='rectangular', max_iter=100):\n",
    "        '''\n",
    "        dimensions - Array-like, containing the size of the output\n",
    "        layer in each dimension.\n",
    "        \n",
    "        topology - The neighborhood relation between output-layer neurons.\n",
    "        The default topology is rectangular. A future improvement would be\n",
    "        to implement a hexagonal topology option.\n",
    "        \n",
    "        max_iter - The maximum number of epochs before the algorithm stops\n",
    "        '''\n",
    "        self.dimensions = dimensions\n",
    "        self.output_layer = None\n",
    "        self.max_iter = max_iter\n",
    "        self.topology = topology\n",
    "        #Output layer indexes is the cartesian product of the lists containing\n",
    "        #the possible indexes to each dimension of the output layer matrix. That\n",
    "        #is, it is a list containing the indexes to all the positions of the \n",
    "        #output layer. It is used to iterate over the output layer, since the \n",
    "        #number of dimensions it will have is unknown before the execution\n",
    "        indexes_list = [list(range(i)) for i in self.dimensions]\n",
    "        self.output_layer_indexes = itertools.product(*indexes_list)\n",
    "        return\n",
    "    def __weight_initialization(self, num_attr):\n",
    "        '''\n",
    "        Initializes the output layer to a matrix with the dimensions specified\n",
    "        for this map, filled with random unit vectors of dimension num_attr\n",
    "        \n",
    "        num_attr - The number of attributes of the instances this network will\n",
    "        be trained with\n",
    "        '''\n",
    "        self.output_layer = np.zeros(self.dimensions, dtype=object)\n",
    "        for i in self.output_layer_indexes:\n",
    "            self.output_layer[i] = get_random_unit_vector(num_attr)\n",
    "        #Maybe cast the output layer to a regular list here?\n",
    "        return\n",
    "    def __get_output(self, instance):\n",
    "        '''\n",
    "        Calculates the output of each neuron for the provided instance.\n",
    "        Returns a matrix with the same dimensions as the output layer\n",
    "        containing the outputs\n",
    "        '''\n",
    "        output_matrix = np.zeros(self.dimensions)\n",
    "        for i in self.output_layer_indexes:\n",
    "            output_matrix[i] = distance.euclidean(instance, self.output_layer[i])\n",
    "        return output_matrix\n",
    "    def __get_neighbors(self, index, radius):\n",
    "        '''\n",
    "        Returns a matrix containing the indexes of the neurons in distance radius\n",
    "        to the one specified by index.\n",
    "        In order to implement different possible topologies, this should have a different\n",
    "        way of computing the indexes depending on that\n",
    "        '''\n",
    "        indexes_list = [list(range(i-math.ceil(radius/2), i+math.ceil(radius/2)+1)) for i in index]\n",
    "        #Just like obtaining the indexes into the output layer, the indexes to this\n",
    "        #area of the output matrix are obtained by computing the cartesian product \n",
    "        #of the indexes into each dimension, limiting the indexes to the correct range\n",
    "        indexes = np.array(list(itertools.product(*indexes_list)))\n",
    "        #Finally, we divide the indexes in each dimension modulo the size of that dimension,\n",
    "        #in order to obtain the wrapped around indexes\n",
    "        return indexes%self.dimensions\n",
    "    def fit(self, X):\n",
    "        '''\n",
    "        Initializes the output layer neurons to random unit vectors, normalizes\n",
    "        the input vectors, and applies the learning algorithm to the input data, X\n",
    "        \n",
    "        X - The data to train the algorithm on\n",
    "        '''\n",
    "        #Since extended normalization will be used, the inputs will have an extra \n",
    "        #dimension, which is why I add 1 here so the output layer vectors will have\n",
    "        #the number of attributes of an instance plus 1 components\n",
    "        #Weight initialization\n",
    "        self.__weight_initialization(len(X[0]) + 1)\n",
    "        #Input data normalization\n",
    "        X = [extended_normalization(v) for v in X]\n",
    "        #Training\n",
    "        for epoch in range(self.max_iter):\n",
    "            #Chose a vector at random from the training data\n",
    "            input_vector = random.choice(X)\n",
    "            #Get the output for each neuron in the output layer\n",
    "            output_matrix = self.__get_output(input_vector)\n",
    "            #Get the index of the neuron that provides the smallest output\n",
    "            #Np unravel index gives us the multi-dimensional index to a matrix\n",
    "            #of the specified shape given the index into the flattened version of\n",
    "            #the matrix, which np.argmin returns\n",
    "            best_matching_unit = np.unravel_index(np.argmin(output_matrix, axis=None), \n",
    "                                                  output_matrix.shape)\n",
    "            #This would be another way to do it, testing should be done in order \n",
    "            #to determine which of the two is the most efficient. I would think this \n",
    "            #secong one is probably better as the matrix indexes are already computed\n",
    "            #best_matching_unit = self.output_layer_indexes[np.argmin(output_matrix)]\n",
    "            \n",
    "            #Obtain the indexes of the neighbors of the best matching unit within a\n",
    "            #specified radius, including the BMU. Note that the indexes that go out of\n",
    "            #bounds wrap around the matrix\n",
    "            neighbors = self.__get_neighbors(best_matching_unit, 3)\n",
    "        return\n",
    "    def predict(self, x):\n",
    "        '''\n",
    "        Determines the Best Matching Unit for the instance x, and returns the predicted\n",
    "        class for it based on the class associated to the neuron\n",
    "        '''\n",
    "        return\n",
    "    def print_map():\n",
    "        '''\n",
    "        Shows a graphical representation of the output layer\n",
    "        '''\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'indexes' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-463-cba527a2ca58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSOM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-462-407eff30e881>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;31m#specified radius, including the BMU. Note that the indexes that go out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;31m#bounds wrap around the matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mneighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_matching_unit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-462-407eff30e881>\u001b[0m in \u001b[0;36m__get_neighbors\u001b[0;34m(self, index, radius)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m#area of the output matrix are obtained by computing the cartesian product\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m#of the indexes into each dimension, limiting the indexes to the correct range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mindexes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mindexes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;31m#Finally, we divide the indexes in each dimension modulo the size of that dimension,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m#in order to obtain the wrapped around indexes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'indexes' referenced before assignment"
     ]
    }
   ],
   "source": [
    "som = SOM([10, 10])\n",
    "som.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1,2,3],\n",
    "        [1,1,1],\n",
    "        [2,3,4],\n",
    "        [4,2,4],\n",
    "        [2,2,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[[3],[1]],\n",
    "     [[0],[2]],\n",
    "     [[3],[3]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin([np.array(a)[i] for i in [(0,0),(0,1),(1,0),(1,1),(2,0),(2,1)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0, 0)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unravel_index(np.argmin(a, axis=None), a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  8,  9],\n",
       "       [12, 13, 14],\n",
       "       [17, 18, 19]])"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2,3,4,5],\n",
    "             [6,7,8,9,10],\n",
    "             [11,12,13,14,15],\n",
    "             [16,17,18,19,20],\n",
    "             [21,22,23,24,25]])\n",
    "i = [2,2]\n",
    "a[i[0]-1:i[0]+2, i[1]-1:i[1]+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 0), (0, 1), (1, -1), (1, 0), (1, 1)]"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a[range(-2,1), range(-2,1)]\n",
    "cell = [0,0]\n",
    "indexes = [list(range(i-1, i+2)) for i in cell]\n",
    "list(itertools.product(*indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ravel_multi_index([-1,-1],(5,5), mode=\"wrap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1, -1], [-1, 0], [-1, 1], [0, -1], [0, 0], [0, 1], [1, -1], [1, 0], [1, 1]]"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimensions = (5,4)\n",
    "x = [[-1, -1], [-1, 0], [-1, 1], [0, -1], [0, 0], [0, 1], [1, -1], [1, 0], [1, 1]]\n",
    "for d in dimensions:\n",
    "    map(lambda i: x[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[4, 3],\n",
       "        [4, 0],\n",
       "        [4, 1]],\n",
       "\n",
       "       [[0, 3],\n",
       "        [0, 0],\n",
       "        [0, 1]],\n",
       "\n",
       "       [[1, 3],\n",
       "        [1, 0],\n",
       "        [1, 1]]])"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[(-1, -1), (-1, 0), (-1, 1)], [(0, -1), (0, 0), (0, 1)], [(1, -1), (1, 0), (1, 1)]])%(5,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[4, 5, 6]],\n",
       "\n",
       "       [[4, 5, 6]]])"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = [4,4]\n",
    "slices = [list(range(i-1, i+2)) for i in index]\n",
    "a.take(slices, mode=\"wrap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 4, 5], [3, 4, 5]]"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[slice(1, 4, None), slice(2, 5, None), slice(3, 6, None)]"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=[slice(i,j) for i,j in zip([1,2,3], [4,5,6])]\n",
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
