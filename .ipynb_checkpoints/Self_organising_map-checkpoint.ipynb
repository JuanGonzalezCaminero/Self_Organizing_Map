{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "from sklearn.datasets import load_iris\n",
    "from scipy.spatial import distance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_vector(vector):\n",
    "    '''\n",
    "    Returns the normalized vector of the provided one, a length 1\n",
    "    vector with the same direction as the original.\n",
    "    '''\n",
    "    vector = np.array(vector)\n",
    "    return (vector/math.sqrt(np.sum(pow(vector, 2)))).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extended_normalization(vector):\n",
    "    '''\n",
    "    When two vectors of different lengths but in the same direction are normalized, \n",
    "    the result will be the same for both of them.\n",
    "    \n",
    "    In order to avoid collisions of normalized vectors, an extended normalization can\n",
    "    be applied, where an extra dimension is added to the vector to be normalized. By\n",
    "    adding a component of length 1 in the new dimension and normalizing the result,\n",
    "    it is ensured that no two vectors which were originally in the same dimensions\n",
    "    will produce the same output.\n",
    "    '''\n",
    "    vector = np.append(vector, 1)\n",
    "    return (vector/math.sqrt(np.sum(pow(vector, 2)))).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_unit_vector(components):\n",
    "    '''\n",
    "    Returns a random vector of length 1 with the required number of components\n",
    "    '''\n",
    "    return normalize_vector([random.random() for i in range(components)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SOM:\n",
    "    def __init__ (self, dimensions, topology='rectangular', max_iter=100, \n",
    "                  initial_learning_rate=0.0001, initial_neighborhood_radius=0,\n",
    "                 labels=[], output_layer=[]):\n",
    "        '''\n",
    "        dimensions - Array-like, containing the size of the output\n",
    "        layer in each dimension.\n",
    "        \n",
    "        topology - The neighborhood relation between output-layer neurons.\n",
    "        The default topology is rectangular. A future improvement would be\n",
    "        to implement a hexagonal topology option.\n",
    "        \n",
    "        max_iter - The maximum number of epochs before the algorithm stops\n",
    "        \n",
    "        initial_learning_rate - The, you guessed it, initial learning rate\n",
    "        \n",
    "        initial_neighborhood_radius - If zero, helf the size of the smallest output layer\n",
    "        dimension will be used as the initial radius, else, this will be used\n",
    "        \n",
    "        labels - If not [], this is used instead of creating a new labels matrix.\n",
    "        useful for loading previous models\n",
    "        \n",
    "        output_layer - If not [], the output layer is set to this\n",
    "        '''\n",
    "        self.dimensions = dimensions\n",
    "        self.output_layer = None if output_layer==[] else output_layer\n",
    "        self.max_iter = max_iter\n",
    "        self.topology = topology\n",
    "        self.initial_learning_rate = initial_learning_rate\n",
    "        self.initial_neighborhood_radius = initial_neighborhood_radius if\\\n",
    "                                    initial_neighborhood_radius>0 else\\\n",
    "                                    math.floor((np.min(dimensions)-1)/2)\n",
    "        #Output layer indexes is the cartesian product of the lists containing\n",
    "        #the possible indexes to each dimension of the output layer matrix. That\n",
    "        #is, it is a list containing the indexes to all the positions of the \n",
    "        #output layer. It is used to iterate over the output layer, since the \n",
    "        #number of dimensions it will have is unknown before the execution\n",
    "        indexes_list = [list(range(i)) for i in self.dimensions]\n",
    "        self.output_layer_indexes = list(itertools.product(*indexes_list))\n",
    "        #The labels for each output neuron, meaning that an instance that has \n",
    "        #a neuron as its BMU will be classified using the label corresponding to \n",
    "        #that neuron. The matrix contains tuples indicating the label and the\n",
    "        #distance to the closest match there has been for that neuron. The label\n",
    "        #corresponds to the class of that match. If a closer match is found, the\n",
    "        #label is updated.\n",
    "        #Although all labels are initialized to zero, an infinite distance ensures\n",
    "        #all will be updated when the training begins\n",
    "        if labels == []:\n",
    "            self.labels = np.zeros(self.dimensions, dtype=object)\n",
    "            for i in self.output_layer_indexes:\n",
    "                self.labels[i]=[0, math.inf]\n",
    "        else:\n",
    "            self.labels = labels\n",
    "        return\n",
    "    @staticmethod\n",
    "    def load_model(path):\n",
    "        '''\n",
    "        Loads the state of the model from a json file and returns a SOM instance\n",
    "        '''\n",
    "        f=open(path, 'r')\n",
    "        string_data = f.read()\n",
    "        som_data = json.loads(string_data)\n",
    "        f.close\n",
    "        som = SOM(som_data['dimensions'],\n",
    "                  output_layer = np.array(som_data['output_layer']),\n",
    "                 labels = np.array(som_data['labels']),\n",
    "                 max_iter = som_data['max_iter'],\n",
    "                 topology = som_data['topology'],\n",
    "                 initial_learning_rate = som_data['initial_learning_rate'],\n",
    "                 initial_neighborhood_radius = som_data['initial_neighborhood_radius'])\n",
    "        return som\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        '''\n",
    "        Saves the state of the model to the file indicated by path\n",
    "        '''\n",
    "        f=open(path+\".json\", 'w')\n",
    "        state={'dimensions': self.dimensions,\n",
    "                'output_layer': self.output_layer.tolist(),\n",
    "                'labels': self.labels.tolist(),\n",
    "                'max_iter': self.max_iter,\n",
    "                'topology': self.topology,\n",
    "                'initial_learning_rate': self.initial_learning_rate,\n",
    "                'initial_neighborhood_radius': self.initial_neighborhood_radius}\n",
    "        f.write(json.dumps(state))\n",
    "        f.close\n",
    "        return\n",
    "    def get_labels(self):\n",
    "        '''\n",
    "        Returns the matrix with the class associated to each output neuron\n",
    "        '''\n",
    "        return self.labels\n",
    "    def __weight_initialization(self, num_attr):\n",
    "        '''\n",
    "        Initializes the output layer to a matrix with the dimensions specified\n",
    "        for this map, filled with random unit vectors of dimension num_attr\n",
    "        \n",
    "        num_attr - The number of attributes of the instances this network will\n",
    "        be trained with\n",
    "        '''\n",
    "        self.output_layer = np.zeros(self.dimensions, dtype=object)\n",
    "        for i in self.output_layer_indexes:\n",
    "            self.output_layer[i] = get_random_unit_vector(num_attr)\n",
    "        #Maybe cast the output layer to a regular list here?\n",
    "        return\n",
    "    def __get_output(self, instance):\n",
    "        '''\n",
    "        Calculates the output of each neuron for the provided instance.\n",
    "        Returns a matrix with the same dimensions as the output layer\n",
    "        containing the outputs\n",
    "        '''\n",
    "        output_matrix = np.zeros(self.dimensions)\n",
    "        for i in self.output_layer_indexes:\n",
    "            output_matrix[i] = distance.euclidean(instance, self.output_layer[i])\n",
    "        return output_matrix\n",
    "    def __update_labels(self, output_matrix, instance_class):\n",
    "        '''\n",
    "        Update the labels matrix. If this instance is a closer match for\n",
    "        a neuron than any previous one, the neuron will be labelled with\n",
    "        the instace's class and the distance stored\n",
    "        \n",
    "        output_matrix - The distances from this instance to each output neuron\n",
    "        \n",
    "        instance_class - The class associated to the instance\n",
    "        '''\n",
    "        for i in self.output_layer_indexes:\n",
    "            if output_matrix[i] < self.labels[i][1]:\n",
    "                self.labels[i][0]=int(instance_class)\n",
    "                self.labels[i][1]=float(output_matrix[i])\n",
    "        return\n",
    "    def __get_neighbors(self, index, radius):\n",
    "        '''\n",
    "        Returns a matrix containing the indexes of the neurons in distance radius\n",
    "        to the one specified by index.\n",
    "        In order to implement different possible topologies, this should have a different\n",
    "        way of computing the indexes depending on that\n",
    "        '''\n",
    "        indexes_list = [list(range(i-math.ceil(radius/2), i+math.ceil(radius/2)+1)) for i in index]\n",
    "        #Just like obtaining the indexes into the output layer, the indexes to this\n",
    "        #area of the output matrix are obtained by computing the cartesian product \n",
    "        #of the indexes into each dimension, limiting the indexes to the correct range\n",
    "        indexes = np.array(list(itertools.product(*indexes_list)))\n",
    "        #Finally, we divide the indexes in each dimension modulo the size of that dimension,\n",
    "        #in order to obtain the wrapped around indexes.\n",
    "        #Indexes are casted to tuples for their use as array indexes\n",
    "        return [tuple(i) for i in indexes%self.dimensions]\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        '''\n",
    "        Initializes the output layer neurons to random unit vectors, normalizes\n",
    "        the input vectors, and applies the learning algorithm to the input data, X\n",
    "        \n",
    "        X - The data to train the algorithm on\n",
    "        \n",
    "        Y - The class of each instance\n",
    "        '''\n",
    "        #Since extended normalization will be used, the inputs will have an extra \n",
    "        #dimension, which is why I add 1 here so the output layer vectors will have\n",
    "        #the number of attributes of an instance plus 1 components\n",
    "        #Weight initialization\n",
    "        self.__weight_initialization(len(X[0]) + 1)\n",
    "        #Input data normalization\n",
    "        X = [extended_normalization(v) for v in X]\n",
    "        #Training\n",
    "        for epoch in range(self.max_iter):\n",
    "            #print(\"Epoch: \" + str(epoch))\n",
    "            #The neighborhood radius depends on the current epoch\n",
    "            neighborhood_radius = max(self.initial_neighborhood_radius-epoch, 0)\n",
    "            #Compute learning rate for this iteration\n",
    "            learning_rate = self.initial_learning_rate/(1+epoch)\n",
    "            #In order to chose inputs at random, create an array with the indexes\n",
    "            #for each instance and reorder it at random\n",
    "            instance_indexes=list(range(len(X)))\n",
    "            random.shuffle(instance_indexes)\n",
    "            \n",
    "            for instance_index in instance_indexes:\n",
    "                #Chose a vector at random from the training data\n",
    "                input_vector = X[instance_index]\n",
    "                #Get the output for each neuron in the output layer\n",
    "                output_matrix = self.__get_output(input_vector)\n",
    "                #Get the index of the neuron that provides the smallest output\n",
    "                #Np unravel index gives us the multi-dimensional index to a matrix\n",
    "                #of the specified shape given the index into the flattened version of\n",
    "                #the matrix, which np.argmin returns\n",
    "                best_matching_unit = np.unravel_index(np.argmin(output_matrix, axis=None), \n",
    "                                                      output_matrix.shape)\n",
    "                #This would be another way to do it, testing should be done in order \n",
    "                #to determine which of the two is the most efficient. I would think this \n",
    "                #secong one is probably better as the matrix indexes are already computed\n",
    "                #best_matching_unit = self.output_layer_indexes[np.argmin(output_matrix)]\n",
    "\n",
    "                #Obtain the indexes of the neighbors of the best matching unit within a\n",
    "                #specified radius, including the BMU. Note that the indexes that go out of\n",
    "                #bounds wrap around the matrix\n",
    "\n",
    "                #This is an alternative way to compute the radius\n",
    "                #The neighborhood radius decreases as the training progresses, and is \n",
    "                #computed based on the current epoch, the maximum number of epochs\n",
    "                #and the initial radius (I could find no formula for doing it so I just\n",
    "                #chose this as it seemed reasonable. However, I assume there are much \n",
    "                #better ways of doing it)\n",
    "                #I will scale the remaining number of iterations to the range\n",
    "                #[0, initial_radius], and round up the result\n",
    "                #https://stats.stackexchange.com/questions/281162/scale-a-number-between-a-range\n",
    "                #current_radius = ((max_epoch-current_epoch)-0/max_epoch-0)*(initial_radius-0)+0\n",
    "                #neighborhood_radius = ((self.max_iter-epoch)/self.max_iter)\\\n",
    "                #                        *self.initial_neighborhood_radius\n",
    "\n",
    "                neighbors = self.__get_neighbors(best_matching_unit, neighborhood_radius)\n",
    "\n",
    "                #I will use a simple neighborhood function: 1 for the BMU's neighbors, and \n",
    "                #0 for the rest. More complex options would involve using different values\n",
    "                #for the BMU's neighbors based on various factors such as their distance\n",
    "                #to the BMU\n",
    "                #The function I will use to update the weights makes the assumption that \n",
    "                #both the inputs and the output layer weights are normalized, which they\n",
    "                #are, in this implementation:\n",
    "                #w_i(t+1) = (w_i(t)+α(t)x_v)/(‖w_i(t)+α(t)x_v‖)\n",
    "                #Where w_i(t) is the element i of the weights vector of the neuron\n",
    "                #in iteration t, α(t) is the learning rate for iteration t, and x \n",
    "                #is the input vector. The division by its module serves to normalize\n",
    "                #the vector again\n",
    "                #As α(t), I will use initial_learning_rate/(1+current_epoch)\n",
    "\n",
    "                #Update the weights of the BMU and it's neighbors\n",
    "                for n in neighbors:\n",
    "                    self.output_layer[n] = normalize_vector(self.output_layer[n]+\n",
    "                                                            learning_rate*np.array(input_vector))\n",
    "        #Update the labels matrix. \n",
    "        for instance_index in range(len(X)):\n",
    "            #Get the output for the instance\n",
    "            output_matrix = self.__get_output(X[instance_index])\n",
    "            #Update the labels\n",
    "            self.__update_labels(output_matrix, Y[instance_index])\n",
    "        return\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        Determines the Best Matching Unit for each instance in X, and returns the predicted\n",
    "        class for it based on the class associated to the neuron\n",
    "        '''\n",
    "        #Normalize the instances in X\n",
    "        X = [extended_normalization(v) for v in X]\n",
    "        predictions = []\n",
    "        for instance in X:\n",
    "            #Get the output for each neuron in the output layer\n",
    "            output_matrix = self.__get_output(instance)\n",
    "            #Get the index of the BMU\n",
    "            best_matching_unit = np.unravel_index(np.argmin(output_matrix, axis=None), \n",
    "                                                  output_matrix.shape)\n",
    "            #Get the label associated to that neuron and store it\n",
    "            predictions.append(self.labels[best_matching_unit][0])\n",
    "        return predictions\n",
    "    def print_map():\n",
    "        '''\n",
    "        Shows a graphical representation of the output layer\n",
    "        '''\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()[\"data\"]\n",
    "target = load_iris()[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "som = SOM([12, 8], max_iter=100)\n",
    "som.fit(X_train, y_train)\n",
    "som.save_model(\"iris_neuron_labeling\")\n",
    "prediction = som.predict(X_test)\n",
    "accuracy_score(y_test, prediction, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training set images load\n",
    "f = open(\"train-images-idx3-ubyte\", 'rb')\n",
    "magic_number = int.from_bytes(f.read(4), \"big\")\n",
    "images_count = int.from_bytes(f.read(4), \"big\")\n",
    "rows = int.from_bytes(f.read(4), \"big\")\n",
    "cols = int.from_bytes(f.read(4), \"big\")\n",
    "mnist_train_x = []\n",
    "for image in range(images_count):\n",
    "    instance = []\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            instance.append(int.from_bytes(f.read(1), \"big\", signed=False))\n",
    "    mnist_train_x.append(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training set labels load\n",
    "f = open(\"train-labels-idx1-ubyte\", 'rb')\n",
    "magic_number = int.from_bytes(f.read(4), \"big\")\n",
    "items_count = int.from_bytes(f.read(4), \"big\")\n",
    "mnist_train_y = []\n",
    "for image in range(items_count):\n",
    "    mnist_train_y.append(int.from_bytes(f.read(1), \"big\", signed=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test set images load\n",
    "f = open(\"t10k-images-idx3-ubyte\", 'rb')\n",
    "magic_number = int.from_bytes(f.read(4), \"big\")\n",
    "images_count = int.from_bytes(f.read(4), \"big\")\n",
    "rows = int.from_bytes(f.read(4), \"big\")\n",
    "cols = int.from_bytes(f.read(4), \"big\")\n",
    "mnist_test_x = []\n",
    "for image in range(images_count):\n",
    "    instance = []\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            instance.append(int.from_bytes(f.read(1), \"big\", signed=False))\n",
    "    mnist_test_x.append(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test set labels load\n",
    "f = open(\"t10k-labels-idx1-ubyte\", 'rb')\n",
    "magic_number = int.from_bytes(f.read(4), \"big\")\n",
    "items_count = int.from_bytes(f.read(4), \"big\")\n",
    "mnist_test_y = []\n",
    "for image in range(items_count):\n",
    "    mnist_test_y.append(int.from_bytes(f.read(1), \"big\", signed=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "som = SOM([12, 8], max_iter=100)\n",
    "som.fit(mnist_train_x, mnist_train_y)\n",
    "som.save_model(\"mnist_neuron_labeling\")\n",
    "prediction = som.predict(mnist_test_x)\n",
    "accuracy_score(mnist_test_y, prediction, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = som.predict(mnist_test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3215"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(mnist_test_y, prediction, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:26: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "/home/juan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:48: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
     ]
    }
   ],
   "source": [
    "som=SOM.load_model(\"mnist_neuron_labeling.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(mnist_test_y, prediction, normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
